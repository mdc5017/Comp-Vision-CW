{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DN4-heart-stomach.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdc5017/Comp-Vision-CW/blob/main/colab_DN4_heart_stomach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol9GDQ7M-PJ_"
      },
      "source": [
        "This file is used to test the trained model on heart and stomach tissue. \\\n",
        "If you want to test different network architectures, please modify the import file below in DN4_Test_5way5shot.py.\\\n",
        "And change the --resume parameter to the corresponding directory. ![tmp.PNG](data:image/png;base64,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)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAPm73FB1KSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab8a79d7-a6f8-4cc6-a65a-6fba5ee3e45d"
      },
      "source": [
        "import time\n",
        "import h5py\n",
        "import copy\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from numpy import zeros, newaxis\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "!pip install pytorch-msssim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "!git clone https://github.com/Blair129/DN4-master_new.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-msssim\n",
            "  Downloading pytorch_msssim-0.2.1-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-msssim) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-msssim) (3.10.0.2)\n",
            "Installing collected packages: pytorch-msssim\n",
            "Successfully installed pytorch-msssim-0.2.1\n",
            "Cloning into 'DN4-master_new'...\n",
            "remote: Enumerating objects: 347, done.\u001b[K\n",
            "remote: Counting objects: 100% (347/347), done.\u001b[K\n",
            "remote: Compressing objects: 100% (223/223), done.\u001b[K\n",
            "remote: Total 347 (delta 165), reused 289 (delta 111), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (347/347), 15.76 MiB | 24.71 MiB/s, done.\n",
            "Resolving deltas: 100% (165/165), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEl_Ppu-B-7s"
      },
      "source": [
        "Download Heart Tissue Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6BrLNLiiii-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bd72d57-6f69-451b-bd6c-8062a551aa67"
      },
      "source": [
        "# Heart tissue data, you can use the command below to download the data \n",
        "# or upload the data from your local computer to the directory /content/\n",
        "!gdown --id 1GxGqqe3mbmRnqTQPB42rSEM7y-UZwBVW\n",
        "!unzip -q /content/heart_few_shot_data_train.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1GxGqqe3mbmRnqTQPB42rSEM7y-UZwBVW\n",
            "To: /content/heart_few_shot_data_train.zip\n",
            "100% 56.6M/56.6M [00:00<00:00, 155MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuFsJuwvCCV_"
      },
      "source": [
        "Download Stomach Tissue Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qox4kpvTjqMa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a495165b-1ac5-4a7d-8040-d725eef68be1"
      },
      "source": [
        "# If you want to test the model on the stomach tissue, use the command below\n",
        "# or upload the data to the directory /content/\n",
        "!gdown --id 1wI_ff0oGqaMp60MtkkPJw1ndUJn5wy5X\n",
        "!unzip -q '/content/stomach_classification_dataset.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wI_ff0oGqaMp60MtkkPJw1ndUJn5wy5X\n",
            "To: /content/stomach_classification_dataset.zip\n",
            "100% 62.1M/62.1M [00:01<00:00, 55.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KgD3HA3sNRop",
        "outputId": "9f5b2ec0-d623-4be5-b741-201fd819cf8a"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J96nbpniO8D",
        "outputId": "d0b8b2ae-986f-4e27-936e-fed6f795daec"
      },
      "source": [
        "import os\n",
        "!pip install patchify\n",
        "\n",
        "\n",
        "from patchify import patchify, unpatchify\n",
        "%cd /content/content/heart_few_shot_data_train/images\n",
        "\n",
        "\n",
        "path = \"/content/content/heart_few_shot_data_train/images\"\n",
        "outPath =\"/content/content/heart_few_shot_data_train_patches/images\" #specify outPath where do we want to save patches\n",
        "\n",
        "\n",
        "for image_path in os.listdir():\n",
        "    if image_path.endswith(\".jpg\"):\n",
        "      img = cv.imread(path_name+'/'+image_path)\n",
        "      print(\"hi\")\n",
        "      print(str(outPath)+\"/\"+image_path.strip('.jpg')+\"_3.jpg\")\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: patchify in /usr/local/lib/python3.7/dist-packages (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.7/dist-packages (from patchify) (1.19.5)\n",
            "/content/content/heart_few_shot_data_train/images\n",
            "hi\n",
            "/content/content/heart_few_shot_data_train_patches/images/7100_3.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvP3u9hfCgXe",
        "outputId": "577fc101-b41b-4864-8d7e-5680c21f2f7f"
      },
      "source": [
        "# divide images in 4 patches and input these to test function\n",
        "\n",
        "import os\n",
        "!pip install patchify\n",
        "\n",
        "\n",
        "from patchify import patchify, unpatchify\n",
        "%cd /content/content/heart_few_shot_data_train/images\n",
        "\n",
        "\n",
        "path_name = \"/content/content/heart_few_shot_data_train/images\"\n",
        "outPath =\"/content/content/heart_few_shot_data_train_patches/images\" #specify outPath where do we want to save patches\n",
        "\n",
        "\n",
        "for image_path in os.listdir():\n",
        "    if image_path.endswith(\".jpg\"):\n",
        "      img = cv.imread(path_name+'/'+image_path)\n",
        "\n",
        "      #image_name = os.path.splitext(image_path)[0]\n",
        "      ##########################################\n",
        "      # At first vertical devide image         #\n",
        "      ##########################################\n",
        "      # start vertical devide image      \n",
        "      heightOriginal = img.shape[0]\n",
        "      widthOriginal = img.shape[1]\n",
        "\n",
        "      height = img.shape[0]\n",
        "      width = img.shape[1]\n",
        "      # Cut the image in half\n",
        "      width_cutoff = width // 2\n",
        "      left1 = img[:, :width_cutoff]\n",
        "      right1 = img[:, width_cutoff:]\n",
        "      # finish vertical devide image\n",
        "              \n",
        "      ##########################################\n",
        "      # At first Horizontal devide left1 image #\n",
        "      ##########################################\n",
        "      #rotate image LEFT1 to 90 CLOCKWISE\n",
        "      img = cv.rotate(left1, cv.ROTATE_90_CLOCKWISE)\n",
        "      # start vertical devide image\n",
        "      height = img.shape[0]\n",
        "      width = img.shape[1]\n",
        "      # Cut the image in half\n",
        "      width_cutoff = width // 2\n",
        "      l1 = img[:, :width_cutoff]\n",
        "      l2 = img[:, width_cutoff:]\n",
        "      # finish vertical devide image\n",
        "      #rotate image to 90 COUNTERCLOCKWISE\n",
        "      l1 = cv.rotate(l1, cv.ROTATE_90_COUNTERCLOCKWISE)\n",
        "      # resize the image into original size\n",
        "      l1 = cv.resize(l1,(widthOriginal,heightOriginal))\n",
        "      #save\n",
        "      cv.imwrite(str(outPath)+\"/\"+image_path.strip('.jpg')+\"_1.jpg\", l1)\n",
        "      #rotate image to 90 COUNTERCLOCKWISE\n",
        "      l2 = cv.rotate(l2, cv.ROTATE_90_COUNTERCLOCKWISE)\n",
        "      #save\n",
        "      cv.imwrite(str(outPath)+\"/\"+image_path.strip('.jpg')+\"_2.jpg\", l2)\n",
        "      ##########################################\n",
        "      # At first Horizontal devide right1 image#\n",
        "      ##########################################\n",
        "      #rotate image RIGHT1 to 90 CLOCKWISE\n",
        "      img = cv.rotate(right1, cv.ROTATE_90_CLOCKWISE)\n",
        "      # resize the image into original size\n",
        "      l2 = cv.resize(l2, (widthOriginal, heightOriginal))\n",
        "      # start vertical devide image\n",
        "      height = img.shape[0]\n",
        "      width = img.shape[1]\n",
        "      # Cut the image in half\n",
        "      width_cutoff = width // 2\n",
        "      r1 = img[:, :width_cutoff]\n",
        "      r2 = img[:, width_cutoff:]\n",
        "      # finish vertical devide image\n",
        "      #rotate image to 90 COUNTERCLOCKWISE\n",
        "      r1 = cv.rotate(r1, cv.ROTATE_90_COUNTERCLOCKWISE)      \n",
        "      # resize the image into original size\n",
        "      r1 = cv.resize(r1, (widthOriginal, heightOriginal))\n",
        "      #save\n",
        "      cv.imwrite(str(outPath)+\"/\"+image_path.strip('.jpg')+\"_3.jpg\", r1)\n",
        "      #rotate image to 90 COUNTERCLOCKWISE\n",
        "      r2 = cv.rotate(r2, cv.ROTATE_90_COUNTERCLOCKWISE)      \n",
        "      # resize the image into original size\n",
        "      r2 = cv.resize(r2, (widthOriginal, heightOriginal))\n",
        "      #save\n",
        "      cv.imwrite(str(outPath)+\"/\"+image_path.strip('.jpg')+\"_4.jpg\", r2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: patchify in /usr/local/lib/python3.7/dist-packages (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.7/dist-packages (from patchify) (1.19.5)\n",
            "/content/content/heart_few_shot_data_train/images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "as_e9PnjK7pf",
        "outputId": "9f127e66-0beb-40fa-fe9d-ec547a00b7ed"
      },
      "source": [
        "import csv\n",
        "outPath =\"/content/content/heart_few_shot_data_train_patches\" #specify outPath where do we want to save patches\n",
        "imageFolderPath =\"/content/content/heart_few_shot_data_train_patches/images\" #specify outPath where do we want to save patches\n",
        "\n",
        "with open(outPath,\"w\",newline='')as f:\n",
        "        b_csv = csv.writer(f, dialect='excel')\n",
        "        # write the first row\n",
        "        b_csv.writerow(['filename', 'label'])\n",
        "        # read image patches names\n",
        "        for image_path in os.listdir(imageFolderPath):\n",
        "            #print(image_path)\n",
        "            # write image patches names\n",
        "            b_csv = csv.writer(f,dialect='excel')\n",
        "            b_csv.writerow(['queryimages'+'/'+image_path ,'2'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-68fb35060732>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimageFolderPath\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/content/heart_few_shot_data_train_patches/images\"\u001b[0m \u001b[0;31m#specify outPath where do we want to save patches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutPath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mb_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdialect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'excel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# write the first row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/content/content/heart_few_shot_data_train_patches'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0CGdS55g5yi"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "ryziX2hQFhce",
        "outputId": "2cd90fad-4990-43e3-f87c-e616bdd18783"
      },
      "source": [
        "\n",
        "#for image_path in os.listdir():\n",
        " # if image_path.endswith(\"\")\n",
        "  #    print(image_path)\n",
        "        # read the file\n",
        " #       im = cv.imread(path)\n",
        "\n",
        "        # split image into patches        \n",
        "  #      im_patches = image_slicer.slice(im, 4)\n",
        "\n",
        "        # create full output path, 'example.jpg' \n",
        "        # becomes 'rotate_example.jpg', save the file to disk\n",
        "   #     fullpath = os.path.join(outPath, image_path)\n",
        "    #    misc.imsave(fullpath, im_Patches)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-65-6c6ee9523321>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    if image_path.endswith(\"g\")\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZpWD0oGCqTl",
        "outputId": "15404446-9299-4bdc-e6b1-43440bf05f59"
      },
      "source": [
        "cd /content/DN4-master_new/DN4-master"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DN4-master_new/DN4-master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiWdYOY7qz4t"
      },
      "source": [
        "If you want to test the model on heart tissue, run the command below\\\n",
        "The trained models are in the results folder, change the dir below to test other models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IOdK2-YmFTe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d40ad4da-c7c4-4bab-d6db-6edf68e585ae"
      },
      "source": [
        "!python DN4_Test_5way5shot.py --resume /content/DN4-master_new/DN4-master/results/DN4_DA_heart_Conv64F_3Way_5Shot_K3_Transformer/model_best.pth.tar --basemodel Conv64F  --dataset_dir '/content/content/heart_few_shot_data_train_patches'  --way_num 3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(basemodel='Conv64F', beta1=0.5, clamp_lower=-0.01, clamp_upper=0.01, cuda=True, data_name='miniImageNet', dataset_dir='/content/content/heart_few_shot_data_train_patches', episodeSize=1, episode_test_num=600, episode_train_num=10000, episode_val_num=1000, epochs=30, imageSize=84, lr=0.005, mode='test', nc=3, neighbor_k=3, ngpu=1, outf='./results/DN4_miniImageNet_Conv64F_3Way_5Shot_K3', print_freq=100, query_num=15, resume='/content/DN4-master_new/DN4-master/results/DN4_DA_heart_Conv64F_3Way_5Shot_K3_Transformer/model_best.pth.tar', shot_num=5, testepisodeSize=1, way_num=3, workers=8)\n",
            "initialization method [normal]\n",
            "=> no checkpoint found at '/content/DN4-master_new/DN4-master/results/DN4_DA_heart_Conv64F_3Way_5Shot_K3_Transformer/model_best.pth.tar'\n",
            "FourLayer_64F(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (slf_attn): MultiHeadAttention(\n",
            "    (w_qs): Linear(in_features=64, out_features=64, bias=False)\n",
            "    (w_ks): Linear(in_features=64, out_features=64, bias=False)\n",
            "    (w_vs): Linear(in_features=64, out_features=64, bias=False)\n",
            "    (attention): ScaledDotProductAttention(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (softmax): Softmax(dim=2)\n",
            "    )\n",
            "    (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    (fc): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (imgtoclass): ImgtoClass_Metric()\n",
            ")\n",
            "\n",
            "............Start testing............\n",
            "===================================== Round 0 =====================================\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Traceback (most recent call last):\n",
            "  File \"DN4_Test_5way5shot.py\", line 306, in <module>\n",
            "    prec1, accuracies_all = validate(test_loader, model, criterion, epoch_index, F_txt)\n",
            "  File \"DN4_Test_5way5shot.py\", line 106, in validate\n",
            "    for episode_index, (query_images, query_targets, support_images, support_targets) in enumerate(val_loader):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1203, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1229, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 434, in reraise\n",
            "    raise exception\n",
            "FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/DN4-master_new/DN4-master/dataset/datasets_csv.py\", line 316, in __getitem__\n",
            "    temp_img = self.loader(query_dir[j])\n",
            "  File \"/content/DN4-master_new/DN4-master/dataset/datasets_csv.py\", line 43, in default_loader\n",
            "    return pil_loader(path)\n",
            "  File \"/content/DN4-master_new/DN4-master/dataset/datasets_csv.py\", line 18, in pil_loader\n",
            "    with open(path, 'rb') as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/content/heart_few_shot_data_train_patches/images/7158.jpg'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c04uvTY7K4v"
      },
      "source": [
        "If you want to test the model on stomach tissue, run the command below\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnXwCFeYaEj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786f9cfe-75e0-4579-8f0d-ccf59c8f64b9"
      },
      "source": [
        "!python DN4_Test_5way5shot.py --resume /content/DN4-master_new/DN4-master/results/DN4_DA_stomach_Conv64F_3Way_5Shot_K3_Transformer/model_best.pth.tar --basemodel Conv64F  --dataset_dir '/content/stomach_classification_dataset'  --way_num 3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(basemodel='Conv64F', beta1=0.5, clamp_lower=-0.01, clamp_upper=0.01, cuda=True, data_name='miniImageNet', dataset_dir='/content/stomach_classification_dataset', episodeSize=1, episode_test_num=600, episode_train_num=10000, episode_val_num=1000, epochs=30, imageSize=84, lr=0.005, mode='test', nc=3, neighbor_k=3, ngpu=1, outf='./results/DN4_miniImageNet_Conv64F_3Way_5Shot_K3', print_freq=100, query_num=15, resume='/content/DN4-master_new/DN4-master/results/DN4_DA_stomach_Conv64F_3Way_5Shot_K3_Transformer/model_best.pth.tar', shot_num=5, testepisodeSize=1, way_num=3, workers=8)\n",
            "initialization method [normal]\n",
            "=> loading checkpoint '/content/DN4-master_new/DN4-master/results/DN4_DA_stomach_Conv64F_3Way_5Shot_K3_Transformer/model_best.pth.tar'\n",
            "=> loaded checkpoint '/content/DN4-master_new/DN4-master/results/DN4_DA_stomach_Conv64F_3Way_5Shot_K3_Transformer/model_best.pth.tar' (epoch 2)\n",
            "FourLayer_64F(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (slf_attn): MultiHeadAttention(\n",
            "    (w_qs): Linear(in_features=64, out_features=64, bias=False)\n",
            "    (w_ks): Linear(in_features=64, out_features=64, bias=False)\n",
            "    (w_vs): Linear(in_features=64, out_features=64, bias=False)\n",
            "    (attention): ScaledDotProductAttention(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "      (softmax): Softmax(dim=2)\n",
            "    )\n",
            "    (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    (fc): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (imgtoclass): ImgtoClass_Metric()\n",
            ")\n",
            "\n",
            "............Start testing............\n",
            "===================================== Round 0 =====================================\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Test-(2): [100/600]\tTime 0.186 (0.209)\tLoss 0.159 (0.247)\tPrec@1 100.000 (91.683)\n",
            "Test-(2): [200/600]\tTime 0.192 (0.200)\tLoss 0.086 (0.256)\tPrec@1 100.000 (91.144)\n",
            "Test-(2): [300/600]\tTime 0.190 (0.197)\tLoss 0.315 (0.265)\tPrec@1 93.333 (90.698)\n",
            "Test-(2): [400/600]\tTime 0.193 (0.195)\tLoss 0.067 (0.260)\tPrec@1 100.000 (90.889)\n",
            "Test-(2): [500/600]\tTime 0.186 (0.194)\tLoss 0.146 (0.259)\tPrec@1 93.333 (90.938)\n",
            " * Prec@1 91.133 Best_prec1 80.067\n",
            "Test accuracy 91.13333 h 0.5672685\n",
            "Test accuracy 91.1 h 1.0527687\n",
            "Test accuracy 90.73333 h 1.0629306\n",
            "Test accuracy 91.566666 h 1.007201\n",
            "===================================== Round 1 =====================================\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Test-(2): [100/600]\tTime 0.195 (0.208)\tLoss 0.378 (0.263)\tPrec@1 80.000 (90.627)\n",
            "Test-(2): [200/600]\tTime 0.192 (0.200)\tLoss 0.266 (0.253)\tPrec@1 86.667 (91.310)\n",
            "Test-(2): [300/600]\tTime 0.191 (0.198)\tLoss 0.061 (0.251)\tPrec@1 100.000 (91.274)\n",
            "Test-(2): [400/600]\tTime 0.192 (0.197)\tLoss 0.164 (0.250)\tPrec@1 93.333 (91.172)\n",
            "Test-(2): [500/600]\tTime 0.186 (0.196)\tLoss 0.510 (0.253)\tPrec@1 73.333 (91.164)\n",
            " * Prec@1 91.467 Best_prec1 80.067\n",
            "Test accuracy 91.46666 h 0.5757396\n",
            "Test accuracy 91.6 h 1.0404125\n",
            "Test accuracy 91.166664 h 1.0021592\n",
            "Test accuracy 91.63333 h 1.0605148\n",
            "===================================== Round 2 =====================================\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Test-(2): [100/600]\tTime 0.205 (0.208)\tLoss 0.153 (0.246)\tPrec@1 93.333 (91.683)\n",
            "Test-(2): [200/600]\tTime 0.215 (0.200)\tLoss 0.275 (0.244)\tPrec@1 93.333 (91.609)\n",
            "Test-(2): [300/600]\tTime 0.186 (0.197)\tLoss 0.070 (0.244)\tPrec@1 100.000 (91.495)\n",
            "Test-(2): [400/600]\tTime 0.189 (0.195)\tLoss 0.303 (0.242)\tPrec@1 86.667 (91.554)\n",
            "Test-(2): [500/600]\tTime 0.185 (0.194)\tLoss 0.197 (0.244)\tPrec@1 86.667 (91.577)\n",
            " * Prec@1 91.389 Best_prec1 80.067\n",
            "Test accuracy 91.388885 h 0.5576428\n",
            "Test accuracy 91.86667 h 0.9779104\n",
            "Test accuracy 91.23333 h 1.0518168\n",
            "Test accuracy 91.066666 h 1.1124609\n",
            "===================================== Round 3 =====================================\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Test-(2): [100/600]\tTime 0.185 (0.207)\tLoss 0.101 (0.237)\tPrec@1 100.000 (91.683)\n",
            "Test-(2): [200/600]\tTime 0.182 (0.199)\tLoss 0.268 (0.241)\tPrec@1 93.333 (91.675)\n",
            "Test-(2): [300/600]\tTime 0.188 (0.196)\tLoss 0.366 (0.240)\tPrec@1 86.667 (91.960)\n",
            "Test-(2): [400/600]\tTime 0.187 (0.194)\tLoss 0.346 (0.242)\tPrec@1 86.667 (91.804)\n",
            "Test-(2): [500/600]\tTime 0.183 (0.193)\tLoss 0.058 (0.242)\tPrec@1 100.000 (91.816)\n",
            " * Prec@1 91.600 Best_prec1 80.067\n",
            "Test accuracy 91.59999 h 0.55484813\n",
            "Test accuracy 91.53333 h 0.99034196\n",
            "Test accuracy 91.76667 h 1.0386747\n",
            "Test accuracy 91.5 h 1.0536654\n",
            "===================================== Round 4 =====================================\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Test-(2): [100/600]\tTime 0.185 (0.210)\tLoss 0.100 (0.290)\tPrec@1 100.000 (89.241)\n",
            "Test-(2): [200/600]\tTime 0.183 (0.200)\tLoss 0.219 (0.267)\tPrec@1 86.667 (90.813)\n",
            "Test-(2): [300/600]\tTime 0.194 (0.197)\tLoss 0.070 (0.254)\tPrec@1 100.000 (91.650)\n",
            "Test-(2): [400/600]\tTime 0.187 (0.196)\tLoss 0.107 (0.252)\tPrec@1 100.000 (91.571)\n",
            "Test-(2): [500/600]\tTime 0.187 (0.194)\tLoss 0.179 (0.250)\tPrec@1 100.000 (91.577)\n",
            " * Prec@1 91.367 Best_prec1 80.067\n",
            "Test accuracy 91.36667 h 0.6000091\n",
            "Test accuracy 92.0 h 1.0483044\n",
            "Test accuracy 91.23333 h 1.0558901\n",
            "Test accuracy 90.86667 h 1.0582354\n",
            "----------------------------------------------------------------\n",
            "Aver_accuracy: 91.391106 Aver_h 0.5711016297340393\n",
            "Aver_accuracy: 91.62 Aver_h 1.0219476103782654\n",
            "Aver_accuracy: 91.22667 Aver_h 1.0422942876815795\n",
            "Aver_accuracy: 91.32667 Aver_h 1.0584154844284057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBYap88MBtSp"
      },
      "source": [
        "If you want to train the model yourself please check the DN4 github and follow the training the instructions."
      ]
    }
  ]
}